{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AprendizajeProfundo-Practico1",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caropilardiaz/DeepLearning/blob/master/AprendizajeProfundo_Practico1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfvgScKQuyYp",
        "colab_type": "text"
      },
      "source": [
        "# **Aprendizaje Profundo - Pr&aacute;ctico 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN5THsdzvE--",
        "colab_type": "text"
      },
      "source": [
        "Integrantes:\n",
        "\n",
        "\n",
        "*   Buzzi, Sergio\n",
        "*   Diaz, Carolina\n",
        "*   Fabro, Juan\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27-6jOfSscPF",
        "colab_type": "text"
      },
      "source": [
        "# **Consigna:**\n",
        "\n",
        "1.   Construir un pipeline de clasificación con un modelo Keras MLP. Pueden comenzar con una versión simplicada que sólo tenga una capa de Input donde pasen los valores de las columnas de *one-hot-encodings*.\n",
        "2.   Entrenar uno o varios modelos (con dos o tres es suficiente, veremos más de esto en el práctico 2). Evaluar los modelos en el conjunto de dev y test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJVRKx8ugbLe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "pip install --upgrade pip\n",
        "pip install --upgrade tensorflow-gpu==2.0.0\n",
        "pip install --upgrade mlflow graphviz pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXGbcVelgRYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn\n",
        "import argparse\n",
        "import mlflow\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "seaborn.set_style('whitegrid')\n",
        "seaborn.set_palette('colorblind')\n",
        "seaborn.set_context('paper')\n",
        "\n",
        "TARGET_COL = 'AdoptionSpeed'\n",
        " \n",
        "SHUFFLE_BUFFER_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67b0ZyJbhjRh",
        "colab_type": "code",
        "outputId": "b7a47ab3-637c-419e-faaf-08f907080bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"TensorFlow Version: {} - Is GPU available: {}\".format(tf.__version__, tf.test.is_gpu_available()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow Version: 2.0.0 - Is GPU available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5YSIgEZhjU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okJBk-3LhjYc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9imMP1qhjOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DIRECTORY = '/content/drive/My Drive/practico_aprendizaje_profundo/petfinder_dataset/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwwGkOoqh2aN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_dataset(dataset_dir):\n",
        "\n",
        "    # Read train dataset (and maybe dev, if you need to...)\n",
        "    dataset, dev_dataset = train_test_split(\n",
        "        pandas.read_csv(os.path.join(dataset_dir, 'train.csv')), test_size=0.2)\n",
        "         \n",
        "    test_dataset = pandas.read_csv(os.path.join(dataset_dir, 'test.csv'))\n",
        "    \n",
        "    print('Training samples {}, test_samples {}'.format(\n",
        "        dataset.shape[0], test_dataset.shape[0]))\n",
        "    \n",
        "    return dataset, dev_dataset, test_dataset\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfjCMkpZh2k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_features(df, one_hot_columns, numeric_columns, embedded_columns, test=False):\n",
        "    direct_features = []\n",
        "\n",
        "    # Create one hot encodings\n",
        "    for one_hot_col, max_value in one_hot_columns.items():\n",
        "        direct_features.append(tf.keras.utils.to_categorical(df[one_hot_col] - 1, max_value))\n",
        "       \n",
        "    \n",
        "    # Concatenate all features that don't need further embedding into a single matrix.\n",
        "    features = {'direct_features': numpy.hstack(direct_features)}\n",
        "\n",
        "    # Create embedding columns - nothing to do here. We will use the zero embedding for OOV\n",
        "    for embedded_col in embedded_columns.keys():\n",
        "        features[embedded_col] = df[embedded_col].values\n",
        "\n",
        "    # Agregado por JPA -- Create and append numeric columns - Don't forget to normalize!\n",
        "    for n_col in numeric_columns:\n",
        "        features[n_col] =  df[n_col].values - df[n_col].mean() / df[n_col].std()\n",
        "        \n",
        "    if not test:\n",
        "        nlabels = df[TARGET_COL].unique().shape[0]\n",
        "        # Convert labels to one-hot encodings\n",
        "        targets = tf.keras.utils.to_categorical(df[TARGET_COL], nlabels)\n",
        "    else:\n",
        "        targets = None\n",
        "    \n",
        "    return features, targets"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWlvBV5dh2i9",
        "colab_type": "code",
        "outputId": "9519f142-5c52-49c5-c755-40b4afe35b63",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dataset, dev_dataset, test_dataset = load_dataset(DATA_DIRECTORY)\n",
        "nlabels = dataset[TARGET_COL].unique().shape[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training samples 8465, test_samples 4411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH0NkyPgh2hE",
        "colab_type": "code",
        "outputId": "cd9a1664-ec1d-4066-ed07-3312087d2484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "# a Esto lo hacemos para ver en que columnas usamos one-hot-encoding y en cuales embeddings\n",
        "print(\"Cantidad de valores distintos por feature:\")\n",
        "print(\"******************************\")\n",
        "for i in dataset.columns.values:\n",
        "    print(i + \": \" + str(dataset[i].unique().shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cantidad de valores distintos por feature:\n",
            "******************************\n",
            "Type: 2\n",
            "Age: 95\n",
            "Breed1: 159\n",
            "Breed2: 109\n",
            "Gender: 3\n",
            "Color1: 7\n",
            "Color2: 7\n",
            "Color3: 6\n",
            "MaturitySize: 4\n",
            "FurLength: 3\n",
            "Vaccinated: 3\n",
            "Dewormed: 3\n",
            "Sterilized: 3\n",
            "Health: 3\n",
            "Quantity: 19\n",
            "Fee: 63\n",
            "State: 13\n",
            "Description: 8042\n",
            "AdoptionSpeed: 5\n",
            "PID: 8465\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDfYfpD1yjsL",
        "colab_type": "text"
      },
      "source": [
        "En base a estos resultados definimos a que features aplicamos one-hot y a cuales embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S21w_AINh2eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "one_hot_columns = {\n",
        "    one_hot_col: dataset[one_hot_col].max()\n",
        "    for one_hot_col in ['Type', 'Gender', 'Color1', 'Color2', 'Color3', 'MaturitySize', 'FurLength',\n",
        "                       'Vaccinated', 'Dewormed', 'Sterilized', 'Health']\n",
        "}\n",
        "embedded_columns = {\n",
        "    embedded_col: dataset[embedded_col].max() + 1\n",
        "    for embedded_col in ['Breed1', 'Breed2', 'State']\n",
        "}\n",
        "numeric_columns = ['Age', 'Fee', 'Quantity']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSSX_4kiVAG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Obtenemos los distintos datasets (train, validation y test)\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "X_train, y_train = process_features(dataset, one_hot_columns, numeric_columns, embedded_columns)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(BATCH_SIZE).shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n",
        "\n",
        "X_dev, y_dev = process_features(dev_dataset, one_hot_columns, numeric_columns, embedded_columns)\n",
        "\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((X_dev, y_dev)).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4x6RbMI9iVKj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_kagg, y_kagg = process_features(test_dataset, one_hot_columns, numeric_columns, embedded_columns, test=True)\n",
        "\n",
        "kagg_ds = tf.data.Dataset.from_tensor_slices(X_kagg).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLTRD4Gsilbr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMf1ht1BzeBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DROPOUT_RATE = 0.25\n",
        "HIDDEN_LAYER_SIZE = 36\n",
        "DIRECT_FEATURES_INPUT_SHAPE = (X_train['direct_features'].shape[1],)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_ubNOcFilhl",
        "colab_type": "code",
        "outputId": "5801457c-3d02-479d-9bdc-dc1534a57bc4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Add one input and one embedding for each embedded column\n",
        "embedding_layers = []\n",
        "inputs = []\n",
        "\n",
        "for embedded_col, max_value in embedded_columns.items():\n",
        "    input_layer = layers.Input(shape=(1,), name=embedded_col)\n",
        "    inputs.append(input_layer)\n",
        "    # Define the embedding layer\n",
        "    embedding_size = int(max_value / 4)\n",
        "    embedding_layers.append(\n",
        "        tf.squeeze(layers.Embedding(input_dim=max_value, output_dim=embedding_size)(input_layer), axis=-2))\n",
        "    \n",
        "    print('Adding embedding of size {} for layer {}'.format(embedding_size, embedded_col))\n",
        "\n",
        "# Add the direct features already calculated\n",
        "direct_features_input = layers.Input(shape=DIRECT_FEATURES_INPUT_SHAPE, name='direct_features')\n",
        "inputs.append(direct_features_input)\n",
        "            \n",
        "# Concatenate everything together\n",
        "features = layers.concatenate(embedding_layers + [direct_features_input])\n",
        "\n",
        "dense1 = layers.Dense(HIDDEN_LAYER_SIZE, activation='relu')(features)\n",
        "\n",
        "drop1 = layers.Dropout(DROPOUT_RATE)(dense1)\n",
        "\n",
        "dense2 = layers.Dense(HIDDEN_LAYER_SIZE / 2, activation='relu')(drop1)\n",
        "\n",
        "drop2 = layers.Dropout(DROPOUT_RATE)(dense2)\n",
        "\n",
        "dense3 = layers.Dense(HIDDEN_LAYER_SIZE / 4, activation='relu')(drop2)\n",
        "\n",
        "output_layer = layers.Dense(nlabels, activation='softmax')(dense3)\n",
        "\n",
        "model = models.Model(inputs=inputs, outputs=output_layer)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Adding embedding of size 77 for layer Breed1\n",
            "Adding embedding of size 77 for layer Breed2\n",
            "Adding embedding of size 10350 for layer State\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3_Tja07ilfU",
        "colab_type": "code",
        "outputId": "22408518-0dc4-41c2-c8f3-8d4bd6d863a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "Breed1 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "Breed2 (InputLayer)             [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "State (InputLayer)              [(None, 1)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 1, 77)        23716       Breed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 77)        23716       Breed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 10350)     428510700   State[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorFlow [(None, 77)]         0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_1 (TensorFl [(None, 77)]         0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Squeeze_2 (TensorFl [(None, 10350)]      0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "direct_features (InputLayer)    [(None, 45)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 10549)        0           tf_op_layer_Squeeze[0][0]        \n",
            "                                                                 tf_op_layer_Squeeze_1[0][0]      \n",
            "                                                                 tf_op_layer_Squeeze_2[0][0]      \n",
            "                                                                 direct_features[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 36)           379800      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 36)           0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 18)           666         dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 18)           0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 9)            171         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 5)            50          dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 428,938,819\n",
            "Trainable params: 428,938,819\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLhbaL6ti323",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mlflow\n",
        "mlflow.set_experiment('ejemplo')\n",
        "\n",
        "with mlflow.start_run(nested=True):\n",
        "    # Log model hiperparameters first\n",
        "    mlflow.log_param('hidden_layer_size', HIDDEN_LAYER_SIZE)\n",
        "    mlflow.log_param('embedded_columns', embedded_columns)\n",
        "    mlflow.log_param('one_hot_columns', one_hot_columns)\n",
        "    mlflow.log_param('numerical_columns', numeric_columns)  \n",
        "    mlflow.log_param('train_dataset.shuffke', True)  \n",
        "    mlflow.log_param('dropout', DROPOUT_RATE)\n",
        "    # Train\n",
        "    epochs = 12\n",
        "    history = model.fit(train_ds, epochs=epochs)\n",
        "    \n",
        "    # Evaluate\n",
        "    loss, accuracy = model.evaluate(test_ds)\n",
        "    print(\"*** Test loss: {} - accuracy: {}\".format(loss, accuracy))\n",
        "    mlflow.log_metric('epochs', epochs)\n",
        "    mlflow.log_metric('loss', loss)\n",
        "    mlflow.log_metric('accuracy', accuracy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zUIbsIUi309",
        "colab_type": "code",
        "outputId": "13949c76-0bcc-498a-b630-d3dc4da2e84f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "epochs = 13\n",
        "history = model.fit(train_ds, epochs=epochs)\n",
        "history"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/13\n",
            "85/85 [==============================] - 273s 3s/step - loss: 1.5575 - accuracy: 0.2491\n",
            "Epoch 2/13\n",
            "85/85 [==============================] - 255s 3s/step - loss: 1.4959 - accuracy: 0.2806\n",
            "Epoch 3/13\n",
            "85/85 [==============================] - 256s 3s/step - loss: 1.4659 - accuracy: 0.2949\n",
            "Epoch 4/13\n",
            "85/85 [==============================] - 255s 3s/step - loss: 1.4556 - accuracy: 0.3126\n",
            "Epoch 5/13\n",
            "85/85 [==============================] - 256s 3s/step - loss: 1.4436 - accuracy: 0.3116\n",
            "Epoch 6/13\n",
            "85/85 [==============================] - 254s 3s/step - loss: 1.4369 - accuracy: 0.3262\n",
            "Epoch 7/13\n",
            "85/85 [==============================] - 256s 3s/step - loss: 1.4341 - accuracy: 0.3333\n",
            "Epoch 8/13\n",
            "85/85 [==============================] - 254s 3s/step - loss: 1.4288 - accuracy: 0.3309\n",
            "Epoch 9/13\n",
            "85/85 [==============================] - 254s 3s/step - loss: 1.4210 - accuracy: 0.3343\n",
            "Epoch 10/13\n",
            "85/85 [==============================] - 256s 3s/step - loss: 1.4140 - accuracy: 0.3380\n",
            "Epoch 11/13\n",
            "85/85 [==============================] - 254s 3s/step - loss: 1.4130 - accuracy: 0.3399\n",
            "Epoch 12/13\n",
            "85/85 [==============================] - 255s 3s/step - loss: 1.4090 - accuracy: 0.3475\n",
            "Epoch 13/13\n",
            "85/85 [==============================] - 254s 3s/step - loss: 1.4063 - accuracy: 0.3453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fde5d46dac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeCWxsQIi3t_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizamos las predicciones obtenidas\n",
        "predictions = numpy.argmax(model.predict(test_ds), axis=1)\n",
        "seaborn.countplot(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8Nlzp1wjiil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pandas.DataFrame( list(zip( test_dataset['PID'], numpy.argmax(model.predict(kagg_ds), axis=1))), \n",
        "                              columns=[\"PID\", \"AdoptionSpeed\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v5_Ec6vjjfz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission.to_csv(DATA_DIRECTORY + \"submision_20191113_2329.csv\", header=True, index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubWX3igNjjlk",
        "colab_type": "code",
        "outputId": "78b46bbd-1e5b-4011-863b-626e0cd05525",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print(history.history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'loss': [1.5401608597507015, 1.4894305121877527, 1.465494959155836, 1.454129143783628, 1.4448032731215628, 1.4374748585988837, 1.428235229696667, 1.4190483054534542, 1.4135040135617378, 1.4086707830429077, 1.4043831196467833, 1.3992141708423593], 'accuracy': [0.25304192, 0.2786769, 0.29604253, 0.31329003, 0.31293562, 0.32793856, 0.3344359, 0.33951566, 0.34270525, 0.34790313, 0.3463674, 0.35640875]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt0SMLvKjjo0",
        "colab_type": "code",
        "outputId": "a5fbab04-6509-45a1-80da-ac3073acacf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 920
        }
      },
      "source": [
        "dir(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_chief_worker_only',\n",
              " '_keras_api_names',\n",
              " '_keras_api_names_v1',\n",
              " 'epoch',\n",
              " 'history',\n",
              " 'model',\n",
              " 'on_batch_begin',\n",
              " 'on_batch_end',\n",
              " 'on_epoch_begin',\n",
              " 'on_epoch_end',\n",
              " 'on_predict_batch_begin',\n",
              " 'on_predict_batch_end',\n",
              " 'on_predict_begin',\n",
              " 'on_predict_end',\n",
              " 'on_test_batch_begin',\n",
              " 'on_test_batch_end',\n",
              " 'on_test_begin',\n",
              " 'on_test_end',\n",
              " 'on_train_batch_begin',\n",
              " 'on_train_batch_end',\n",
              " 'on_train_begin',\n",
              " 'on_train_end',\n",
              " 'params',\n",
              " 'set_model',\n",
              " 'set_params',\n",
              " 'validation_data']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuBto1POjjjp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}